# Phase 7.1: Single Test Runner Strategy - Research

**Researched:** 2026-02-06
**Domain:** Multi-agent test coordination / GSD workflow optimization
**Confidence:** HIGH

## Summary

This phase addresses a concrete problem observed during Phase 7 execution: when multiple GSD executor agents run in parallel (Wave 2 had 5 simultaneous agents), each agent independently runs `pnpm test` after every task commit. With ~992 test files and vitest using up to 16 worker processes, this creates massive CPU contention, potential file locking issues (observed: `index.lock` conflicts, eslint concurrent reformatting), and redundant work.

The research identified three viable approaches at different levels of intervention. The recommended approach modifies the GSD workflow layer (plan templates, executor behavior, and execute-phase orchestration) rather than modifying the test runner itself. The key insight is: test coordination belongs in the orchestrator, not in the test tool.

The current GSD architecture already has the right primitives: the execute-phase orchestrator spawns agents per wave, waits for all to complete, then runs verification. The change is to remove per-task `pnpm test` from individual executor plans and instead have a single designated test run after all agents in a wave complete their code changes.

**Primary recommendation:** Remove `pnpm test` from individual executor task verification. Add a wave-level test run (executed by the orchestrator or a dedicated test-runner agent) between waves. Individual agents verify their changes with targeted tests only (e.g., `npx vitest run path/to/relevant.test.js`).

## Standard Stack

This phase does not introduce new libraries. It modifies GSD workflow documents and plan templates.

### Core

| Tool | Version | Purpose | Why Standard |
|------|---------|---------|--------------|
| `vitest` | ^4.0.18 | Test runner (already installed) | Project standard; pool: forks, up to 16 local workers |
| GSD workflow | N/A | Plan/execute/verify lifecycle | Existing orchestration layer handles wave-based execution |

### Supporting

| Tool | Version | Purpose | When to Use |
|------|---------|---------|-------------|
| vitest JSON reporter | built-in | Machine-readable test output | When test results need to be shared across agents |
| `npx vitest run <path>` | built-in | Targeted single-file test execution | For per-task verification (replaces full suite) |

### Alternatives Considered

| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| Workflow-level coordination | vitest `--shard` + `--merge-reports` | Over-engineered for this use case; designed for CI matrix, not local multi-agent |
| JSON result file sharing | vitest blob reporter | Adds complexity; agents can just read terminal output or a JSON file |
| Agent teams (experimental) | Claude Code agent teams with shared task list | Experimental, different paradigm than GSD subagents; would require major workflow rewrite |

## Architecture Patterns

### Current Flow (Problem)

```
execute-phase orchestrator
  |
  +-- Wave 2 (5 parallel agents)
       |
       +-- Agent 07-03: task1 -> pnpm test -> commit -> task2 -> pnpm test -> commit
       +-- Agent 07-04: task1 -> pnpm test -> commit -> task2 -> pnpm test -> commit
       +-- Agent 07-05: task1 -> pnpm test -> commit -> task2 -> pnpm test -> commit
       +-- Agent 07-06: task1 -> pnpm test -> commit -> task2 -> pnpm test -> commit
       +-- Agent 07-07: task1 -> pnpm test -> commit -> task2 -> pnpm test -> commit

Total test runs in Wave 2: ~15 full suite runs (3 tasks avg x 5 agents)
Each run: 992 test files, 16 workers, 2+ minutes
CPU contention: 5 agents x 16 workers = 80 vitest worker processes competing
```

### Pattern 1: Wave-Level Test Gate (RECOMMENDED)

**What:** Move full test suite execution from per-task to per-wave. Individual agents run only targeted tests. The orchestrator runs a single full suite between waves.

**When to use:** Always, for all future phases using parallel wave execution.

```
execute-phase orchestrator
  |
  +-- Wave 2 (5 parallel agents)
  |    |
  |    +-- Agent 07-03: task1 -> targeted test -> commit -> task2 -> targeted test -> commit
  |    +-- Agent 07-04: task1 -> targeted test -> commit -> task2 -> targeted test -> commit
  |    +-- Agent 07-05: task1 -> targeted test -> commit -> task2 -> targeted test -> commit
  |    +-- Agent 07-06: task1 -> targeted test -> commit -> task2 -> targeted test -> commit
  |    +-- Agent 07-07: task1 -> targeted test -> commit -> task2 -> targeted test -> commit
  |
  +-- Wave 2 Test Gate: pnpm test (single run, full suite)
  |    |
  |    +-- PASS -> proceed to Wave 3
  |    +-- FAIL -> report failures, identify responsible agent(s), remediate
  |
  +-- Wave 3 ...
```

**Benefits:**
- Full test runs per wave: 1 (down from ~15)
- No CPU contention between parallel test processes
- Each agent completes faster (targeted test takes seconds vs full suite 2+ minutes)
- Test failures are still caught before dependent work begins (wave boundary)

### Pattern 2: Targeted Test Verification for Agents

**What:** Each agent runs only tests related to the files it modified, not the full suite.

**How agents determine targeted tests:**
```bash
# Option A: Run test files colocated with modified source
# If agent modified src/gateway/auth.js, run src/gateway/auth.test.js
npx vitest run src/gateway/auth.test.js

# Option B: Run the specific test file referenced in the plan
# Plans already specify test files in <verify> sections
npx vitest run path/to/specific.test.js

# Option C: Use vitest --related flag (runs tests affected by changed files)
npx vitest run --related src/gateway/auth.js
```

**When to use:** For every auto task's `<verify>` step within a parallel wave.

### Pattern 3: Test Results Sharing via JSON File

**What:** The wave-level test run writes results to a JSON file. If tests fail, agents responsible for the failures can read the file to understand what broke.

```bash
# Wave-level test run writes JSON results
npx vitest run --reporter=json --outputFile=.planning/test-results/wave-2-results.json

# Failed agents can read this to see which tests failed
cat .planning/test-results/wave-2-results.json | jq '.testResults[] | select(.status == "failed")'
```

**When to use:** Only when the wave-level test gate fails and remediation agents need context.

### Pattern 4: Pre-commit Hook Isolation

**What:** The pre-commit hook (`git-hooks/pre-commit`) runs `eslint --fix` on staged files, which is a major source of concurrent conflicts. Under multi-agent execution, this hook reformats files that other agents are also staging.

**Documented issues from Phase 7:**
- eslint --fix takes 2+ minutes and causes race conditions with concurrent agents
- Hook's `git add` re-stages files that another agent may have modified
- `index.lock` conflicts from concurrent git operations

**Solution approaches (for planner to choose):**
1. **Agents use `--no-verify`** when committing during parallel waves (already done in Phase 7 as workaround)
2. **Run lint as wave-level gate** alongside tests (orchestrator runs `pnpm check` once per wave)
3. **Narrow the pre-commit hook** to only lint staged files without `git add` (prevents re-staging)

### Recommended Project Structure Changes

```
.planning/
  phases/
    07.1-single-test-runner-strategy/
      07.1-RESEARCH.md          # This file
      07.1-01-PLAN.md           # Workflow modifications
  test-results/                  # New: wave test results (gitignored)
    wave-N-results.json          # JSON test output per wave

# Modified workflow files (user's ~/.claude/ directory):
~/.claude/get-shit-done/workflows/execute-phase.md    # Add wave-level test gate
~/.claude/agents/gsd-executor.md                       # Update verification guidance
~/.claude/agents/gsd-planner.md                        # Update plan template guidance
```

### Anti-Patterns to Avoid

- **Running `pnpm test` (full suite) in every task's `<verify>` during parallel execution:** This is the problem being solved. Creates N-agents x M-tasks full test runs per wave.
- **Having each agent poll for test results from another agent:** Adds complexity. The orchestrator already coordinates wave boundaries.
- **Sharding tests across agents:** vitest `--shard` is designed for CI matrix runs across machines, not for multi-agent coordination on a single machine. The agents aren't test runners; they're code writers.
- **Skipping all testing during execution:** Some targeted verification per task is still valuable for fast feedback. The full suite just moves to the wave boundary.

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Test result sharing | Custom IPC between agents | vitest JSON reporter + file | vitest already outputs machine-readable JSON |
| Wave-level test coordination | Custom test orchestration tool | GSD execute-phase workflow modification | Orchestrator already manages waves; add test step |
| Targeted test selection | Custom dependency graph | `vitest run --related <file>` or colocated test convention | vitest already has `--related` flag built in |
| Pre-commit conflict resolution | Custom file locking | `--no-verify` during parallel waves + wave-level lint | Git already supports `--no-verify`; lint once at wave boundary |

**Key insight:** The GSD workflow's execute-phase orchestrator already has the right architecture (wave-based coordination, sequential waves, parallel agents within waves). The fix is adding a test gate step between waves, not building new infrastructure.

## Common Pitfalls

### Pitfall 1: Removing All Testing from Agent Plans

**What goes wrong:** Agents commit broken code that compounds through the wave. By the time the wave-level test runs, many failures are entangled and hard to attribute.
**Why it happens:** Over-correction from "too much testing" to "no testing."
**How to avoid:** Keep targeted tests per task (the specific test file for the modified code). Only remove the full suite run.
**Warning signs:** Agent commits that don't run any test at all.

### Pitfall 2: Wave-Level Test Failure Attribution

**What goes wrong:** Full suite fails at wave boundary but it's unclear which agent's commit caused it. Multiple agents may have introduced different failures.
**Why it happens:** 5 agents each modified different files; a cross-cutting test could fail due to any of them.
**How to avoid:** Use `git bisect` or test against individual agent commits if failures are ambiguous. Consider running tests incrementally against each commit in the wave (slower but precise).
**Warning signs:** Multiple unrelated test failures at wave boundary.

### Pitfall 3: ESLint Conflicts During Parallel Commits

**What goes wrong:** Pre-commit hook runs `eslint --fix .` (entire project), reformats files another agent is working on, causes staging conflicts.
**Why it happens:** The hook applies formatting globally, not just to the staged files' content.
**How to avoid:** Use `--no-verify` during parallel waves. Run `pnpm check` once at the wave boundary.
**Warning signs:** `index.lock` errors, pre-commit hook reverting changes, agents retrying commits.

### Pitfall 4: Targeted Tests Missing Cross-Cutting Regressions

**What goes wrong:** Agent's targeted test passes but the change breaks an unrelated integration test. Not caught until wave boundary.
**Why it happens:** Targeted tests only cover the immediately-modified code, not downstream consumers.
**How to avoid:** Accept this as a design tradeoff. The wave-level test gate catches these. The cost (delayed detection) is much less than the cost of N full suite runs per wave.
**Warning signs:** Wave-level test failures in files none of the agents directly modified.

### Pitfall 5: Vitest Worker Count Contention

**What goes wrong:** Even with targeted tests, if 5 agents each run vitest simultaneously, they spawn 5 x 16 = 80 worker processes.
**Why it happens:** vitest config sets `maxWorkers: Math.max(4, Math.min(16, os.cpus().length))` for each invocation.
**How to avoid:** For targeted single-file tests, use `--maxWorkers=1` or `--no-threads` since a single test file doesn't benefit from parallelism.
**Warning signs:** System slowdown, test timeouts, high CPU usage during targeted tests.

## Code Examples

### Example 1: Wave-Level Test Gate in execute-phase.md

```markdown
<!-- Add after all agents in wave complete, before proceeding to next wave -->

<step name="wave_test_gate">
After all agents in a wave complete:

1. Run full test suite once:
   ```bash
   pnpm test --run
   ```

2. If tests pass: proceed to next wave
3. If tests fail:
   - Parse failure output
   - Identify which files/tests failed
   - Cross-reference with agent commits in this wave
   - Report: "Wave N tests failed. Failures in: [test files]. Likely caused by: [agent plan IDs]"
   - Ask user: remediate or continue?

4. Optionally run lint gate:
   ```bash
   pnpm check
   ```
</step>
```

### Example 2: Targeted Test in Plan Template

```xml
<!-- BEFORE (current plans) -->
<verify>`pnpm test` passes, `pnpm check` passes</verify>

<!-- AFTER (new pattern for parallel wave plans) -->
<verify>
Targeted tests pass:
  `npx vitest run src/gateway/auth.test.js`
  `npx vitest run src/gateway/call.test.js`
Git commit succeeds (with --no-verify during parallel waves)
</verify>
```

### Example 3: JSON Test Results Output

```bash
# Wave-level test with JSON output for failure analysis
npx vitest run --reporter=default --reporter=json \
  --outputFile.json=.planning/test-results/wave-2-results.json

# If failures, extract failing tests:
# (remediation agent reads this)
cat .planning/test-results/wave-2-results.json | \
  node -e "
    const r = JSON.parse(require('fs').readFileSync('/dev/stdin','utf8'));
    r.testResults.filter(t => t.status === 'failed').forEach(t => {
      console.log(t.name);
      t.assertionResults.filter(a => a.status === 'failed').forEach(a => {
        console.log('  FAIL:', a.fullName, '-', a.failureMessages[0]?.split('\n')[0]);
      });
    });
  "
```

### Example 4: Vitest Targeted Run with Limited Workers

```bash
# For single-file targeted test during parallel execution
# Use --maxWorkers=1 to avoid spawning unnecessary processes
npx vitest run --maxWorkers=1 src/specific-file.test.js

# For vitest --related (runs all tests affected by a file change)
npx vitest run --related src/modified-file.js --maxWorkers=2
```

### Example 5: Updated Pre-commit Hook (Optional)

```bash
#!/bin/sh
# Current hook (causes conflicts):
# FILES=$(git diff --cached --name-only --diff-filter=ACMR | sed 's| |\\ |g')
# [ -z "$FILES" ] && exit 0
# echo "$FILES" | xargs pnpm format:fix --no-error-on-unmatched-pattern
# echo "$FILES" | xargs git add

# Option: Skip in parallel mode (agent sets env var)
if [ -n "$GSD_PARALLEL_WAVE" ]; then
  exit 0
fi

# Otherwise run normal hook
FILES=$(git diff --cached --name-only --diff-filter=ACMR | sed 's| |\\ |g')
[ -z "$FILES" ] && exit 0
echo "$FILES" | xargs pnpm format:fix --no-error-on-unmatched-pattern
echo "$FILES" | xargs git add
exit 0
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Each agent runs `pnpm test` per task | Wave-level test gate (proposed) | Phase 7.1 | Reduces test runs from N*M to 1 per wave |
| Pre-commit hook runs globally | `--no-verify` + wave-level lint (proposed) | Phase 7.1 | Eliminates concurrent hook conflicts |
| No targeted test support | `vitest run --related` or specific file | vitest built-in | Fast per-task feedback without full suite |

**Deprecated/outdated:**
- Running `pnpm test` in every `<verify>` element during parallel waves: Replaced by targeted tests + wave-level gate

## Implementation Scope

This phase requires modifications to **workflow documents** (not source code). Specifically:

### Documents to Modify

1. **`~/.claude/get-shit-done/workflows/execute-phase.md`** -- Add wave-level test gate step between `execute_waves` and next wave
2. **`~/.claude/agents/gsd-planner.md`** -- Update plan template guidance to use targeted tests in `<verify>` for parallel plans
3. **`~/.claude/agents/gsd-executor.md`** -- Update verification guidance: targeted tests during parallel waves, full suite only for solo execution

### Documents to Create

4. **A reference document** (e.g., `~/.claude/get-shit-done/references/parallel-testing.md`) -- Guidance for planners on writing verification with targeted vs full suite tests

### Optional Changes

5. **`.gitignore`** -- Add `.planning/test-results/` if JSON result files are used
6. **Pre-commit hook** -- Optionally add parallel-mode bypass (or just document `--no-verify` convention)

### What Does NOT Change

- `vitest.config.js` -- No changes to test runner configuration
- `package.json` -- No new dependencies
- Source code -- No application code changes
- Test files -- No test modifications

## Open Questions

1. **Wave-level test failure remediation flow**
   - What we know: Orchestrator can detect failures and attribute them to agent commits
   - What's unclear: Should remediation be automatic (spawn fix agents) or manual (report to user)?
   - Recommendation: Start with manual (report failures, user decides). Can automate later.

2. **Solo-agent behavior**
   - What we know: When only 1 agent runs in a wave, the full suite per-task is fine (no contention)
   - What's unclear: Should the planner automatically detect single-agent waves and keep full suite in verify?
   - Recommendation: Use targeted tests universally. The wave-level gate always runs the full suite regardless.

3. **Modifying files outside the project repo**
   - What we know: The GSD workflow files live in `~/.claude/` (user's home directory), not in the project repo
   - What's unclear: Should this plan modify those files directly, or just document the changes and let the user apply them?
   - Recommendation: Treat as documentation/instructions that the planner applies when creating future phase plans. The immediate concrete change is the plan template pattern.

4. **Pre-commit hook strategy**
   - What we know: `--no-verify` works but skips all hooks; the hook could be made parallel-safe
   - What's unclear: Is modifying the hook worth it, or is `--no-verify` + wave-level lint sufficient?
   - Recommendation: `--no-verify` + wave-level lint is simpler and proven (used in Phase 7). Skip hook modification.

## Sources

### Primary (HIGH confidence)

- Project codebase: `vitest.config.js` -- Current test configuration (pool: forks, up to 16 workers, 992 test files)
- Project codebase: `git-hooks/pre-commit` -- Current hook implementation (runs eslint --fix globally)
- Project codebase: `.planning/phases/07-security-initial-hardening/07-*-SUMMARY.md` -- Phase 7 execution reports documenting concurrency issues
- GSD workflow: `~/.claude/get-shit-done/workflows/execute-phase.md` -- Current wave-based orchestration
- GSD workflow: `~/.claude/agents/gsd-executor.md` -- Current executor behavior
- GSD workflow: `~/.claude/agents/gsd-planner.md` -- Current plan template patterns

### Secondary (MEDIUM confidence)

- [Vitest Improving Performance](https://vitest.dev/guide/improving-performance) -- Sharding, blob reporter, merge-reports
- [Vitest Reporters](https://vitest.dev/guide/reporters) -- JSON reporter, output file configuration
- [Claude Code Agent Teams](https://code.claude.com/docs/en/agent-teams) -- Agent coordination patterns (context only, not recommended for this phase)

### Tertiary (LOW confidence)

- Web search results on multi-agent test coordination patterns -- Informed general approach but no direct precedent for GSD-specific workflow

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH -- No new tools; leveraging existing vitest features and GSD workflow
- Architecture: HIGH -- Based on direct analysis of Phase 7 execution issues and existing orchestrator architecture
- Pitfalls: HIGH -- Directly observed in Phase 7 summaries (index.lock, eslint conflicts, CPU contention)

**Research date:** 2026-02-06
**Valid until:** 2026-03-06 (stable -- workflow patterns don't change rapidly)
